name: Infrastructure Destruction

on:
  workflow_dispatch:  # Manual trigger only - safe!
    inputs:
      confirm_destroy:
        description: 'Type "DESTROY" to confirm (case-sensitive)'
        required: true
        type: string

# Prevent duplicate runs
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  validate-destroy:
    name: Validate Destruction Request
    runs-on: ubuntu-latest
    steps:
      - name: Validate confirmation
        run: |
          if [ "${{ github.event.inputs.confirm_destroy }}" != "DESTROY" ]; then
            echo "âŒ Invalid confirmation. You must type 'DESTROY' to proceed."
            echo "Received: '${{ github.event.inputs.confirm_destroy }}'"
            exit 1
          fi
          echo "âœ… Destruction confirmed. Proceeding with infrastructure teardown..."

  terraform-destroy:
    name: Destroy All Infrastructure
    runs-on: ubuntu-latest
    needs: validate-destroy
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'us-east-1' }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Download state from artifacts (always try first - most recent in CI/CD)
        uses: actions/download-artifact@v4
        with:
          name: terraform-state
          path: infra/terraform/
          pattern: terraform.tfstate*
          allow-empty: true
        continue-on-error: true

      - name: Check if state exists in artifacts
        id: check-artifacts
        working-directory: infra/terraform
        run: |
          if [ -f terraform.tfstate ] || [ -f terraform.tfstate.backup ]; then
            echo "âœ… State file found in artifacts (most recent from CI/CD)"
            echo "state_exists=true" >> $GITHUB_OUTPUT
            ls -lah terraform.tfstate* || true
          else
            echo "âš ï¸  State file not found in artifacts"
            echo "state_exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Determine backend configuration for fallback
        id: backend-check
        if: steps.check-artifacts.outputs.state_exists == 'false'
        working-directory: infra/terraform
        run: |
          echo "ğŸ” Artifacts missing. Checking backend configuration for fallback..."
          
          # Check backend.tf to determine where state might be stored
          if grep -q 'backend "local"' backend.tf && grep -q 'path = "/mnt/terraform-state' backend.tf; then
            echo "Backend: Local on EBS volume - will fetch from server"
            echo "backend_type=ebs" >> $GITHUB_OUTPUT
          elif grep -q 'backend "s3"' backend.tf; then
            echo "Backend: S3 - state will be fetched during terraform init"
            echo "backend_type=s3" >> $GITHUB_OUTPUT
          else
            echo "Backend: Local in CI/CD runner - artifacts should have it"
            echo "backend_type=local" >> $GITHUB_OUTPUT
          fi

      - name: Fetch state from EBS volume (fallback if artifacts missing)
        if: steps.check-artifacts.outputs.state_exists == 'false' && steps.backend-check.outputs.backend_type == 'ebs'
        working-directory: infra/terraform
        run: |
          echo "ğŸ“¥ Artifacts missing. Fetching state from EBS volume on server..."
          
          # Get server IP from AWS
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=todo-app-server" "Name=instance-state-name,Values=running,stopped,stopping,pending" \
            --query 'Reservations[*].Instances[*].[InstanceId,LaunchTime]' \
            --output text 2>/dev/null | sort -k2 -r | head -1 | awk '{print $1}' || echo "")
          
          if [ -z "$INSTANCE_ID" ] || [ "$INSTANCE_ID" == "None" ]; then
            echo "âš ï¸  No instance found. Cannot fetch state from EBS volume."
            exit 0
          fi
          
          SERVER_IP=$(aws ec2 describe-instances \
            --instance-ids "$INSTANCE_ID" \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --output text 2>/dev/null || echo "")
          
          if [ -z "$SERVER_IP" ] || [ "$SERVER_IP" == "None" ]; then
            echo "âš ï¸  Instance has no public IP. Cannot fetch state."
            exit 0
          fi
          
          echo "Found instance $INSTANCE_ID at $SERVER_IP"
          
          # Setup SSH
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H "$SERVER_IP" >> ~/.ssh/known_hosts 2>/dev/null || true
          
          # Fetch state file from EBS volume
          if scp -o StrictHostKeyChecking=no -i ~/.ssh/id_rsa \
            "${{ secrets.TERRAFORM_SERVER_USER || 'ubuntu' }}@$SERVER_IP:/mnt/terraform-state/terraform.tfstate" \
            terraform.tfstate 2>/dev/null; then
            echo "âœ… Successfully fetched state file from EBS volume!"
            ls -lah terraform.tfstate
          else
            echo "âš ï¸  Could not fetch state file from EBS volume"
          fi
        continue-on-error: true

      - name: Verify state file exists
        id: verify-state
        working-directory: infra/terraform
        run: |
          if [ -f terraform.tfstate ] || [ -f terraform.tfstate.backup ]; then
            echo "âœ… State file found"
            echo "state_exists=true" >> $GITHUB_OUTPUT
            ls -lah terraform.tfstate* || true
          else
            echo "âš ï¸  No state file found"
            echo "This could mean:"
            echo "  - Infrastructure was never created"
            echo "  - State file was manually deleted"
            echo "  - State is in remote backend (S3) and will be fetched during init"
            echo "state_exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Terraform Init
        working-directory: infra/terraform
        run: terraform init

      - name: Create terraform.tfvars from GitHub Secrets
        working-directory: infra/terraform
        run: |
          cat > terraform.tfvars <<EOF
          aws_region = "${{ secrets.AWS_REGION || 'us-east-1' }}"
          instance_type = "${{ secrets.TERRAFORM_INSTANCE_TYPE || 't3.medium' }}"
          key_pair_name = "${{ secrets.TERRAFORM_KEY_PAIR_NAME }}"
          ssh_key_path = "${{ secrets.TERRAFORM_SSH_KEY_PATH || '~/.ssh/id_rsa' }}"
          ssh_cidr = "${{ secrets.TERRAFORM_SSH_CIDR || '0.0.0.0/0' }}"
          server_user = "${{ secrets.TERRAFORM_SERVER_USER || 'ubuntu' }}"
          state_volume_size = ${{ secrets.TERRAFORM_STATE_VOLUME_SIZE || 10 }}
          availability_zone = ""
          skip_ansible_provision = true
          EOF

      - name: Import existing resources if state is missing
        if: steps.verify-state.outputs.state_exists == 'false'
        working-directory: infra/terraform
        run: |
          echo "âš ï¸  State file missing. Attempting to import existing resources..."
          
          # Import security group
          SG_ID=$(aws ec2 describe-security-groups \
            --filters "Name=group-name,Values=todo-app-sg" \
            --query 'SecurityGroups[0].GroupId' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$SG_ID" ] && [ "$SG_ID" != "None" ]; then
            echo "Importing security group: $SG_ID"
            terraform import -var-file=terraform.tfvars aws_security_group.todo_app "$SG_ID" || echo "Security group import failed"
          fi
          
          # Import EC2 instance (get the most recent one if multiple exist)
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=todo-app-server" "Name=instance-state-name,Values=running,stopped,stopping,pending" \
            --query 'Reservations[*].Instances[*].[InstanceId,LaunchTime]' \
            --output text 2>/dev/null | sort -k2 -r | head -1 | awk '{print $1}' || echo "")
          
          if [ -n "$INSTANCE_ID" ] && [ "$INSTANCE_ID" != "None" ]; then
            echo "Importing EC2 instance: $INSTANCE_ID"
            terraform import -var-file=terraform.tfvars aws_instance.todo_app "$INSTANCE_ID" || echo "EC2 instance import failed"
            
            # Import EBS volume
            VOL_ID=$(aws ec2 describe-volumes \
              --filters "Name=attachment.instance-id,Values=$INSTANCE_ID" "Name=tag:Name,Values=terraform-state-storage" \
              --query 'Volumes[0].VolumeId' \
              --output text 2>/dev/null || echo "")
            
            if [ -n "$VOL_ID" ] && [ "$VOL_ID" != "None" ]; then
              echo "Importing EBS volume: $VOL_ID"
              terraform import -var-file=terraform.tfvars aws_ebs_volume.terraform_state "$VOL_ID" || echo "EBS volume import failed"
              
              # Refresh state after volume import
              terraform refresh -var-file=terraform.tfvars || true
              
              # Get device name from volume attachment
              DEVICE=$(aws ec2 describe-volumes --volume-ids "$VOL_ID" --query 'Volumes[0].Attachments[0].Device' --output text 2>/dev/null || echo "")
              
              if [ -n "$DEVICE" ] && [ "$DEVICE" != "None" ]; then
                # Try importing volume attachment - format: <volume_id>:<instance_id>:<device>
                # Note: Device might be /dev/sdf or /dev/nvme1n1 depending on instance type
                echo "Attempting to import volume attachment: $VOL_ID:$INSTANCE_ID:$DEVICE"
                
                # Try the import, but don't fail if it doesn't work
                # The attachment will be destroyed when volume or instance is destroyed
                terraform import -var-file=terraform.tfvars aws_volume_attachment.terraform_state "${VOL_ID}:${INSTANCE_ID}:${DEVICE}" 2>&1 || {
                  echo "âš ï¸  Volume attachment import failed (non-critical - attachment will be destroyed with volume/instance)"
                  echo "This is expected if the attachment format doesn't match exactly"
                }
              else
                echo "âš ï¸  Could not determine device name for volume attachment"
                echo "Skipping attachment import (non-critical)"
              fi
            fi
          fi
          
          echo "âœ… Import complete. Proceeding with destroy..."
        continue-on-error: true

      - name: Check and detach EBS volume if needed
        working-directory: infra/terraform
        run: |
          echo "ğŸ” Checking if EBS volume attachment is in state..."
          
          # Check if volume attachment resource exists in state
          if terraform state list 2>/dev/null | grep -q "aws_volume_attachment.terraform_state"; then
            echo "âœ… Volume attachment is in state - Terraform will handle detachment"
          else
            echo "âš ï¸  Volume attachment NOT in state - checking if volume needs manual detachment"
            
            # Get instance ID from state or AWS
            INSTANCE_ID=$(terraform state show aws_instance.todo_app 2>/dev/null | grep -oP 'id\s+=\s+"\K[^"]+' | head -1 || echo "")
            
            if [ -z "$INSTANCE_ID" ]; then
              # Try to get from AWS by tag
              INSTANCE_ID=$(aws ec2 describe-instances \
                --filters "Name=tag:Name,Values=todo-app-server" "Name=instance-state-name,Values=running,stopped,stopping,pending" \
                --query 'Reservations[*].Instances[*].[InstanceId,LaunchTime]' \
                --output text 2>/dev/null | sort -k2 -r | head -1 | awk '{print $1}' || echo "")
            fi
            
            if [ -n "$INSTANCE_ID" ] && [ "$INSTANCE_ID" != "None" ]; then
              # Check if there's a volume attached to this instance
              VOL_ID=$(aws ec2 describe-volumes \
                --filters "Name=attachment.instance-id,Values=$INSTANCE_ID" "Name=tag:Name,Values=terraform-state-storage" \
                --query 'Volumes[0].VolumeId' \
                --output text 2>/dev/null || echo "")
              
              if [ -n "$VOL_ID" ] && [ "$VOL_ID" != "None" ]; then
                echo "Found attached volume: $VOL_ID on instance: $INSTANCE_ID"
                echo "âš ï¸  Volume attachment not in state - will detach manually before destroy"
                echo "This ensures the volume can be destroyed without being stuck"
                
                # Detach the volume (force detach to avoid hanging)
                aws ec2 detach-volume \
                  --volume-id "$VOL_ID" \
                  --instance-id "$INSTANCE_ID" \
                  --force 2>/dev/null || echo "Volume may already be detached or detaching"
                
                # Wait for detachment to complete
                echo "Waiting for volume to detach..."
                aws ec2 wait volume-available --volume-ids "$VOL_ID" --timeout 60 || echo "Volume detachment may still be in progress"
              else
                echo "No attached volume found - proceeding normally"
              fi
            else
              echo "No instance found - proceeding normally"
            fi
          fi
        continue-on-error: true

      - name: Terraform Plan Destroy
        working-directory: infra/terraform
        run: |
          echo "ğŸ“‹ Generating destroy plan..."
          terraform plan -destroy -var-file=terraform.tfvars -out=destroy.tfplan
          echo ""
          echo "âš ï¸ DESTRUCTION PLAN SUMMARY:"
          terraform show -no-color destroy.tfplan | head -100
        continue-on-error: true

      - name: Terraform Destroy
        working-directory: infra/terraform
        run: |
          echo "ğŸ”¥ Starting infrastructure destruction..."
          echo "This will destroy:"
          echo "  - EC2 instance (and all containers/services on it)"
          echo "  - Security groups"
          echo "  - EBS volumes (including Terraform state volume)"
          echo "  - Volume attachments"
          echo ""
          terraform destroy -auto-approve -var-file=terraform.tfvars
        continue-on-error: true

      - name: Verify Destruction
        working-directory: infra/terraform
        run: |
          echo "ğŸ” Verifying all resources are destroyed..."
          terraform show 2>/dev/null || echo "âœ… State file is empty or invalid (expected after destruction)"
          
          # Try to list any remaining resources
          echo ""
          echo "Checking for orphaned resources..."
          
          # Check for EC2 instances
          INSTANCES=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=todo-app-server" "Name=instance-state-name,Values=running,stopped,stopping" \
            --query 'Reservations[*].Instances[*].InstanceId' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$INSTANCES" ] && [ "$INSTANCES" != "None" ]; then
            echo "âš ï¸ WARNING: Found EC2 instances: $INSTANCES"
            echo "They may still be terminating. Check AWS Console."
          else
            echo "âœ… No EC2 instances found"
          fi
          
          # Check for security groups
          SGS=$(aws ec2 describe-security-groups \
            --filters "Name=group-name,Values=todo-app-sg" \
            --query 'SecurityGroups[*].GroupId' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$SGS" ] && [ "$SGS" != "None" ]; then
            echo "âš ï¸ WARNING: Found security groups: $SGS"
            echo "Attempting to delete..."
            for sg in $SGS; do
              aws ec2 delete-security-group --group-id "$sg" 2>/dev/null || echo "Could not delete $sg (may have dependencies)"
            done
          else
            echo "âœ… No security groups found"
          fi
          
          # Check for EBS volumes
          VOLUMES=$(aws ec2 describe-volumes \
            --filters "Name=tag:Name,Values=terraform-state-storage" \
            --query 'Volumes[*].VolumeId' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$VOLUMES" ] && [ "$VOLUMES" != "None" ]; then
            echo "âš ï¸ WARNING: Found EBS volumes: $VOLUMES"
            echo "Attempting to delete..."
            for vol in $VOLUMES; do
              aws ec2 delete-volume --volume-id "$vol" 2>/dev/null || echo "Could not delete $vol"
            done
          else
            echo "âœ… No EBS volumes found"
          fi

      - name: Clean up local state files
        working-directory: infra/terraform
        run: |
          echo "ğŸ§¹ Cleaning up local state files..."
          rm -f terraform.tfstate terraform.tfstate.backup destroy.tfplan *.tfvars
          echo "âœ… Local state files removed"

      - name: Delete state artifact
        run: |
          echo "ğŸ§¹ Note: Terraform state artifact will be automatically cleaned up after workflow completion"
          echo "GitHub Actions artifacts are retained for 90 days but can be manually deleted"

      - name: Destruction Summary
        if: always()
        run: |
          echo ""
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "ğŸ—‘ï¸  INFRASTRUCTURE DESTRUCTION COMPLETE"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "âœ… Destroyed resources:"
          echo "   - EC2 instance and all services"
          echo "   - Security groups"
          echo "   - EBS volumes"
          echo "   - All containers and applications"
          echo ""
          echo "ğŸ“ Next steps:"
          echo "   1. Verify in AWS Console that all resources are gone"
          echo "   2. Delete any orphaned resources manually if needed"
          echo "   3. Clean up GitHub Actions artifacts (optional)"
          echo "   4. All costs should now be $0.00"
          echo ""
          echo "âš ï¸  IMPORTANT:"
          echo "   - State file has been destroyed"
          echo "   - To recreate infrastructure, run the infrastructure workflow again"
          echo "   - All data on the instance is permanently lost"
          echo ""
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

